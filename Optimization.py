'''
    Вы научитесь:
    - Применять библиотеку SciPy для минимизации функций
    - Делать выбор между градиентными и неградиентными методами оптимизации, исходя из особенностей задачи и ваших пожеланий к итоговому решению

    Инструкция по выполнению:
    Задача №1. Минимизация гладкой функции
    Задача №2. Глобальная оптимизация
    Задача №3. Минимизация негладкой функции

'''


from scipy.optimize import minimize, differential_evolution
import matplotlib.pyplot as plt
import numpy as np

# 1. Минимизация гладкой функции

# Определяем функцию
f = lambda x: np.sin(x / 5.0) * np.exp(x / 10.0) + 5 * np.exp(-x / 2.0)
x = np.arange(1.0, 30.0, 0.25)

#plt.plot(x, f(x))
#plt.show()

x0 = 2 # Задаем начальные задания
x1 = 30

# Минимизируем методом BFGS и получаем значения в точке минимума
result = minimize(f, x0, method = 'BFGS')
#print(round(result['fun'],2))
result_2 = minimize(f, x1, method = 'BFGS')
#print(round(result_2['fun'], 2))
#print(result_2)

# Градиентные методы обычно не решают задачу глобальной оптимизации
# Именно поэтому значения функции в точке минимума при различных начальных значениях настолько разные

# 2. Глобальная оптимизация

# Поиск минимума с помощью дифференциальной эволюции
global_opt = differential_evolution(f, bounds = [(1, 30)])
#print(global_opt)
#print(round(global_opt.fun[0], 2))

# Исходя из графика, мы видим, что диффиренциальная эволюция нашла глобальный минимум
# Всё потому что данная оптимизация по своему устройству предполагает борьбу с локальными минимумами

# Разница между градиентным методом минимизации (BFGS) и методом дифференциальной эволюции:
# - В дифференциальной эволюции за одну итерацию требуется выполнить гораздо больше действий, чем в BFGS.
# (показатель nfev - количество вычислений значения функции)
# - Время работы дифференциальной эволюции быстро растет с увеличением числа аргументов функции.

# 3.Минимизация негладкой функции

x = np.arange(1, 30, 1)
h = lambda x: int(f(x))
y = np.vectorize(h)
plt.plot(x, y(x))
plt.grid(True)
plt.show()

# Находим минимум новой функции с помощью метода BFGS
minim = minimize(h, x0 = 30, method = 'BFGS')
print(minim.fun)

# Находим минимум новой функции с помощью метода дифференциальной эволюции
minim_2 = differential_evolution(h, bounds = [(1, 30)])
print(minim_2.fun)

# BFGS завершил свою работу на первой же итерации (на
# Дифференциальная эволюция не испытывает сложностей из-за отсутствия градиента и успешно находит глобальный минимум
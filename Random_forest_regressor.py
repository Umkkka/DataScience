'''
    Вы научитесь:
    - работать со случайным лесом — одним из наиболее распространенных семейств алгоритмов
    - решать с его помощью задачи регрессии
    - подбирать параметры случайного леса

    Задание:
    - Предсказать возраст ракушки (число колец) по физическим измерениям.

    Инструкция по выполнению:
    1. Загрузите данные из файла abalone.csv.
    2. Преобразуйте признак Sex в числовой: значение F должно перейти в -1, I — в 0, M — в 1.
    3. Разделите содержимое файлов на признаки и целевую переменную.
    4. Обучите случайный лес. Для каждого из вариантов оцените качество работы полученного леса на кросс-валидации по 5 блокам.
       В качестве меры качества воспользуйтесь коэффициентом детерминации.
    5. Определите, при каком минимальном количестве деревьев случайный лес показывает качество на кросс-валидации выше 0.52.

'''


import pandas as pd
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score
from sklearn.model_selection import KFold, cross_val_score

data = pd.read_csv('abalone.csv')

# Преобразовываем значения таблицы "Sex" в численные значения
data['Sex'] = data['Sex'].map(lambda x: 1 if x == 'M' else (-1 if x == 'F' else 0))

# Разделяем набор данных на признаки и целевую переменную
target = data['Rings']
signs = data.drop('Rings', axis = 1)

# Создаем генератор кросс-валидации
kf = KFold(n_splits = 5, random_state = 1, shuffle = True)

# Перебираем количество деревьев - от 1 до 50
for estimators in range(1, 51):
    rfc = RandomForestRegressor(n_estimators = estimators, random_state = 1)
    score = 0
    for train_ind, test_ind in kf.split(signs):
        # Разбиваем выборку на обучающую и тестовую
        X_train, X_test = signs.loc[train_ind], signs.loc[test_ind]
        y_train, y_test = target[train_ind], target[test_ind]
        rfc.fit(X_train, y_train) # Обучаем модель
        # Суммируем коэффициенты детерминации, которые вычисляются по правильному ответу и тому, что выдала наша модель
        # на тестовой выборке
        score += r2_score(y_test, rfc.predict(X_test))
    score = score / 5 # Так как кросс-валидация проводилась по 5 блокам необходимо поделить на 5
    if score > 0.52: # Находим минимальное количество деревьев, на которых качество кросс-валидации леса больше 0.52
        print(estimators, score)
        break

# По мере роста количества деревьев качество на кросс-валидации улучшается (закомментируйте строку с "break")
# Однако это не означает, что нужно брать большое количество деревьев, так как прирост в вычислениях не окупает прирост в качестве